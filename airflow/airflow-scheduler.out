[2024-09-27T14:59:20.783+0200] {executor_loader.py:254} INFO - Loaded executor: SequentialExecutor
[2024-09-27T14:59:20.837+0200] {scheduler_job_runner.py:935} INFO - Starting the scheduler
[2024-09-27T14:59:20.838+0200] {scheduler_job_runner.py:942} INFO - Processing each file at most -1 times
[2024-09-27T14:59:20.842+0200] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 108118
[2024-09-27T14:59:20.844+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T14:59:20.846+0200] {settings.py:63} INFO - Configured default timezone UTC
[2024-09-27T14:59:20.863+0200] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2024-09-27T15:00:51.151+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: predict_model_dag.test_mongo_conn_task manual__2024-09-27T13:00:50+00:00 [scheduled]>
[2024-09-27T15:00:51.151+0200] {scheduler_job_runner.py:495} INFO - DAG predict_model_dag has 0/16 running and queued tasks
[2024-09-27T15:00:51.152+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: predict_model_dag.test_mongo_conn_task manual__2024-09-27T13:00:50+00:00 [scheduled]>
[2024-09-27T15:00:51.155+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: predict_model_dag.test_mongo_conn_task manual__2024-09-27T13:00:50+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T15:00:51.156+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='predict_model_dag', task_id='test_mongo_conn_task', run_id='manual__2024-09-27T13:00:50+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2024-09-27T15:00:51.156+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'predict_model_dag', 'test_mongo_conn_task', 'manual__2024-09-27T13:00:50+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:00:51.162+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'predict_model_dag', 'test_mongo_conn_task', 'manual__2024-09-27T13:00:50+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:00:53.554+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='predict_model_dag', task_id='test_mongo_conn_task', run_id='manual__2024-09-27T13:00:50+00:00', try_number=1, map_index=-1)
[2024-09-27T15:00:53.559+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=predict_model_dag, task_id=test_mongo_conn_task, run_id=manual__2024-09-27T13:00:50+00:00, map_index=-1, run_start_date=2024-09-27 13:00:52.979989+00:00, run_end_date=2024-09-27 13:00:53.101223+00:00, run_duration=0.121234, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=40, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2024-09-27 13:00:51.153023+00:00, queued_by_job_id=38, pid=109082
[2024-09-27T15:00:53.608+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: predict_model_dag.load_model_task manual__2024-09-27T13:00:50+00:00 [scheduled]>
[2024-09-27T15:00:53.608+0200] {scheduler_job_runner.py:495} INFO - DAG predict_model_dag has 0/16 running and queued tasks
[2024-09-27T15:00:53.608+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: predict_model_dag.load_model_task manual__2024-09-27T13:00:50+00:00 [scheduled]>
[2024-09-27T15:00:53.610+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: predict_model_dag.load_model_task manual__2024-09-27T13:00:50+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T15:00:53.610+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='predict_model_dag', task_id='load_model_task', run_id='manual__2024-09-27T13:00:50+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T15:00:53.610+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'predict_model_dag', 'load_model_task', 'manual__2024-09-27T13:00:50+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:00:53.617+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'predict_model_dag', 'load_model_task', 'manual__2024-09-27T13:00:50+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:00:58.949+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='predict_model_dag', task_id='load_model_task', run_id='manual__2024-09-27T13:00:50+00:00', try_number=1, map_index=-1)
[2024-09-27T15:00:58.956+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=predict_model_dag, task_id=load_model_task, run_id=manual__2024-09-27T13:00:50+00:00, map_index=-1, run_start_date=2024-09-27 13:00:56.512029+00:00, run_end_date=2024-09-27 13:00:57.663196+00:00, run_duration=1.151167, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=41, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 13:00:53.609184+00:00, queued_by_job_id=38, pid=109106
[2024-09-27T15:04:20.881+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T15:04:45.358+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: predict_model_dag.test_mongo_conn_task manual__2024-09-27T13:04:44+00:00 [scheduled]>
[2024-09-27T15:04:45.358+0200] {scheduler_job_runner.py:495} INFO - DAG predict_model_dag has 0/16 running and queued tasks
[2024-09-27T15:04:45.359+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: predict_model_dag.test_mongo_conn_task manual__2024-09-27T13:04:44+00:00 [scheduled]>
[2024-09-27T15:04:45.360+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: predict_model_dag.test_mongo_conn_task manual__2024-09-27T13:04:44+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T15:04:45.361+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='predict_model_dag', task_id='test_mongo_conn_task', run_id='manual__2024-09-27T13:04:44+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2024-09-27T15:04:45.361+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'predict_model_dag', 'test_mongo_conn_task', 'manual__2024-09-27T13:04:44+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:04:45.368+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'predict_model_dag', 'test_mongo_conn_task', 'manual__2024-09-27T13:04:44+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:04:47.450+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='predict_model_dag', task_id='test_mongo_conn_task', run_id='manual__2024-09-27T13:04:44+00:00', try_number=1, map_index=-1)
[2024-09-27T15:04:47.452+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=predict_model_dag, task_id=test_mongo_conn_task, run_id=manual__2024-09-27T13:04:44+00:00, map_index=-1, run_start_date=2024-09-27 13:04:46.947116+00:00, run_end_date=2024-09-27 13:04:47.072778+00:00, run_duration=0.125662, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=43, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2024-09-27 13:04:45.359924+00:00, queued_by_job_id=38, pid=111005
[2024-09-27T15:04:47.487+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: predict_model_dag.load_model_task manual__2024-09-27T13:04:44+00:00 [scheduled]>
[2024-09-27T15:04:47.488+0200] {scheduler_job_runner.py:495} INFO - DAG predict_model_dag has 0/16 running and queued tasks
[2024-09-27T15:04:47.488+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: predict_model_dag.load_model_task manual__2024-09-27T13:04:44+00:00 [scheduled]>
[2024-09-27T15:04:47.490+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: predict_model_dag.load_model_task manual__2024-09-27T13:04:44+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T15:04:47.490+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='predict_model_dag', task_id='load_model_task', run_id='manual__2024-09-27T13:04:44+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T15:04:47.491+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'predict_model_dag', 'load_model_task', 'manual__2024-09-27T13:04:44+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:04:47.499+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'predict_model_dag', 'load_model_task', 'manual__2024-09-27T13:04:44+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:04:50.445+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='predict_model_dag', task_id='load_model_task', run_id='manual__2024-09-27T13:04:44+00:00', try_number=1, map_index=-1)
[2024-09-27T15:04:50.447+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=predict_model_dag, task_id=load_model_task, run_id=manual__2024-09-27T13:04:44+00:00, map_index=-1, run_start_date=2024-09-27 13:04:49.073091+00:00, run_end_date=2024-09-27 13:04:49.841372+00:00, run_duration=0.768281, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=44, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 13:04:47.489823+00:00, queued_by_job_id=38, pid=111027
[2024-09-27T15:04:52.722+0200] {dagrun.py:823} ERROR - Marking run <DagRun predict_model_dag @ 2024-09-27 13:04:44+00:00: manual__2024-09-27T13:04:44+00:00, state:running, queued_at: 2024-09-27 13:04:44.920394+00:00. externally triggered: True> failed
[2024-09-27T15:04:52.722+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=predict_model_dag, execution_date=2024-09-27 13:04:44+00:00, run_id=manual__2024-09-27T13:04:44+00:00, run_start_date=2024-09-27 13:04:45.331533+00:00, run_end_date=2024-09-27 13:04:52.722804+00:00, run_duration=7.391271, state=failed, external_trigger=True, run_type=manual, data_interval_start=2024-09-26 00:00:00+00:00, data_interval_end=2024-09-27 00:00:00+00:00, dag_hash=d69314eb4107b40e51220d0a297377f1
[2024-09-27T15:09:20.913+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T15:10:26.823+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: predict_model_dag.test_mongo_conn_task manual__2024-09-27T13:10:25+00:00 [scheduled]>
[2024-09-27T15:10:26.823+0200] {scheduler_job_runner.py:495} INFO - DAG predict_model_dag has 0/16 running and queued tasks
[2024-09-27T15:10:26.824+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: predict_model_dag.test_mongo_conn_task manual__2024-09-27T13:10:25+00:00 [scheduled]>
[2024-09-27T15:10:26.825+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: predict_model_dag.test_mongo_conn_task manual__2024-09-27T13:10:25+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T15:10:26.826+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='predict_model_dag', task_id='test_mongo_conn_task', run_id='manual__2024-09-27T13:10:25+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2024-09-27T15:10:26.826+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'predict_model_dag', 'test_mongo_conn_task', 'manual__2024-09-27T13:10:25+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:10:26.893+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'predict_model_dag', 'test_mongo_conn_task', 'manual__2024-09-27T13:10:25+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:10:31.021+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='predict_model_dag', task_id='test_mongo_conn_task', run_id='manual__2024-09-27T13:10:25+00:00', try_number=1, map_index=-1)
[2024-09-27T15:10:31.027+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=predict_model_dag, task_id=test_mongo_conn_task, run_id=manual__2024-09-27T13:10:25+00:00, map_index=-1, run_start_date=2024-09-27 13:10:28.932830+00:00, run_end_date=2024-09-27 13:10:29.529349+00:00, run_duration=0.596519, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=47, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2024-09-27 13:10:26.824959+00:00, queued_by_job_id=38, pid=114103
[2024-09-27T15:10:35.569+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: predict_model_dag.fetch_data_task manual__2024-09-27T13:10:25+00:00 [scheduled]>
[2024-09-27T15:10:35.590+0200] {scheduler_job_runner.py:495} INFO - DAG predict_model_dag has 0/16 running and queued tasks
[2024-09-27T15:10:35.600+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: predict_model_dag.fetch_data_task manual__2024-09-27T13:10:25+00:00 [scheduled]>
[2024-09-27T15:10:35.606+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: predict_model_dag.fetch_data_task manual__2024-09-27T13:10:25+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T15:10:35.608+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='predict_model_dag', task_id='fetch_data_task', run_id='manual__2024-09-27T13:10:25+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T15:10:35.608+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'predict_model_dag', 'fetch_data_task', 'manual__2024-09-27T13:10:25+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:10:35.670+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'predict_model_dag', 'fetch_data_task', 'manual__2024-09-27T13:10:25+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:10:39.862+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='predict_model_dag', task_id='fetch_data_task', run_id='manual__2024-09-27T13:10:25+00:00', try_number=1, map_index=-1)
[2024-09-27T15:10:39.865+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=predict_model_dag, task_id=fetch_data_task, run_id=manual__2024-09-27T13:10:25+00:00, map_index=-1, run_start_date=2024-09-27 13:10:38.661120+00:00, run_end_date=2024-09-27 13:10:38.888287+00:00, run_duration=0.227167, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=49, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 13:10:35.601124+00:00, queued_by_job_id=38, pid=114200
[2024-09-27T15:10:39.902+0200] {dagrun.py:823} ERROR - Marking run <DagRun predict_model_dag @ 2024-09-27 13:10:25+00:00: manual__2024-09-27T13:10:25+00:00, state:running, queued_at: 2024-09-27 13:10:25.695754+00:00. externally triggered: True> failed
[2024-09-27T15:10:39.902+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=predict_model_dag, execution_date=2024-09-27 13:10:25+00:00, run_id=manual__2024-09-27T13:10:25+00:00, run_start_date=2024-09-27 13:10:26.778490+00:00, run_end_date=2024-09-27 13:10:39.902676+00:00, run_duration=13.124186, state=failed, external_trigger=True, run_type=manual, data_interval_start=2024-09-26 00:00:00+00:00, data_interval_end=2024-09-27 00:00:00+00:00, dag_hash=d69314eb4107b40e51220d0a297377f1
[2024-09-27T15:14:20.955+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T15:19:20.996+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T15:24:21.048+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T15:29:21.094+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T15:34:21.153+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T15:38:17.153+0200] {manager.py:280} WARNING - DagFileProcessorManager (PID=108118) exited with exit code 1 - re-launching
[2024-09-27T15:38:17.159+0200] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 128705
[2024-09-27T15:38:17.177+0200] {settings.py:63} INFO - Configured default timezone UTC
[2024-09-27T15:38:17.204+0200] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2024-09-27T15:39:21.201+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T15:39:23.411+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: predict_model_dag.fetch_data_task scheduled__2024-09-26T00:00:00+00:00 [scheduled]>
[2024-09-27T15:39:23.412+0200] {scheduler_job_runner.py:495} INFO - DAG predict_model_dag has 0/16 running and queued tasks
[2024-09-27T15:39:23.413+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: predict_model_dag.fetch_data_task scheduled__2024-09-26T00:00:00+00:00 [scheduled]>
[2024-09-27T15:39:23.417+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: predict_model_dag.fetch_data_task scheduled__2024-09-26T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T15:39:23.417+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='predict_model_dag', task_id='fetch_data_task', run_id='scheduled__2024-09-26T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T15:39:23.418+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'predict_model_dag', 'fetch_data_task', 'scheduled__2024-09-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:39:23.438+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'predict_model_dag', 'fetch_data_task', 'scheduled__2024-09-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:39:25.835+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='predict_model_dag', task_id='fetch_data_task', run_id='scheduled__2024-09-26T00:00:00+00:00', try_number=1, map_index=-1)
[2024-09-27T15:39:25.838+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=predict_model_dag, task_id=fetch_data_task, run_id=scheduled__2024-09-26T00:00:00+00:00, map_index=-1, run_start_date=2024-09-27 13:39:25.268366+00:00, run_end_date=2024-09-27 13:39:25.419769+00:00, run_duration=0.151403, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=42, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 13:39:23.413800+00:00, queued_by_job_id=38, pid=129347
[2024-09-27T15:39:25.873+0200] {dagrun.py:823} ERROR - Marking run <DagRun predict_model_dag @ 2024-09-26 00:00:00+00:00: scheduled__2024-09-26T00:00:00+00:00, state:running, queued_at: 2024-09-27 13:39:17.288772+00:00. externally triggered: False> failed
[2024-09-27T15:39:25.874+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=predict_model_dag, execution_date=2024-09-26 00:00:00+00:00, run_id=scheduled__2024-09-26T00:00:00+00:00, run_start_date=2024-09-27 13:39:17.309834+00:00, run_end_date=2024-09-27 13:39:25.873925+00:00, run_duration=8.564091, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-26 00:00:00+00:00, data_interval_end=2024-09-27 00:00:00+00:00, dag_hash=d69314eb4107b40e51220d0a297377f1
[2024-09-27T15:39:25.878+0200] {dag.py:4180} INFO - Setting next_dagrun for predict_model_dag to 2024-09-27 00:00:00+00:00, run_after=2024-09-28 00:00:00+00:00
[2024-09-27T15:39:55.194+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: predict_model_dag.test_mongo_conn_task manual__2024-09-27T13:39:54+00:00 [scheduled]>
[2024-09-27T15:39:55.195+0200] {scheduler_job_runner.py:495} INFO - DAG predict_model_dag has 0/16 running and queued tasks
[2024-09-27T15:39:55.197+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: predict_model_dag.test_mongo_conn_task manual__2024-09-27T13:39:54+00:00 [scheduled]>
[2024-09-27T15:39:55.201+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: predict_model_dag.test_mongo_conn_task manual__2024-09-27T13:39:54+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T15:39:55.203+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='predict_model_dag', task_id='test_mongo_conn_task', run_id='manual__2024-09-27T13:39:54+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2024-09-27T15:39:55.205+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'predict_model_dag', 'test_mongo_conn_task', 'manual__2024-09-27T13:39:54+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:39:55.229+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'predict_model_dag', 'test_mongo_conn_task', 'manual__2024-09-27T13:39:54+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:39:59.097+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='predict_model_dag', task_id='test_mongo_conn_task', run_id='manual__2024-09-27T13:39:54+00:00', try_number=1, map_index=-1)
[2024-09-27T15:39:59.103+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=predict_model_dag, task_id=test_mongo_conn_task, run_id=manual__2024-09-27T13:39:54+00:00, map_index=-1, run_start_date=2024-09-27 13:39:57.721505+00:00, run_end_date=2024-09-27 13:39:57.981128+00:00, run_duration=0.259623, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=43, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2024-09-27 13:39:55.198666+00:00, queued_by_job_id=38, pid=129717
[2024-09-27T15:40:04.171+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: predict_model_dag.fetch_data_task manual__2024-09-27T13:39:54+00:00 [scheduled]>
[2024-09-27T15:40:04.175+0200] {scheduler_job_runner.py:495} INFO - DAG predict_model_dag has 0/16 running and queued tasks
[2024-09-27T15:40:04.176+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: predict_model_dag.fetch_data_task manual__2024-09-27T13:39:54+00:00 [scheduled]>
[2024-09-27T15:40:04.179+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: predict_model_dag.fetch_data_task manual__2024-09-27T13:39:54+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T15:40:04.179+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='predict_model_dag', task_id='fetch_data_task', run_id='manual__2024-09-27T13:39:54+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T15:40:04.179+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'predict_model_dag', 'fetch_data_task', 'manual__2024-09-27T13:39:54+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:40:04.188+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'predict_model_dag', 'fetch_data_task', 'manual__2024-09-27T13:39:54+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:40:08.044+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='predict_model_dag', task_id='fetch_data_task', run_id='manual__2024-09-27T13:39:54+00:00', try_number=1, map_index=-1)
[2024-09-27T15:40:08.050+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=predict_model_dag, task_id=fetch_data_task, run_id=manual__2024-09-27T13:39:54+00:00, map_index=-1, run_start_date=2024-09-27 13:40:07.114767+00:00, run_end_date=2024-09-27 13:40:07.298607+00:00, run_duration=0.18384, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=45, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 13:40:04.177692+00:00, queued_by_job_id=38, pid=129954
[2024-09-27T15:40:08.086+0200] {dagrun.py:823} ERROR - Marking run <DagRun predict_model_dag @ 2024-09-27 13:39:54+00:00: manual__2024-09-27T13:39:54+00:00, state:running, queued_at: 2024-09-27 13:39:54.958427+00:00. externally triggered: True> failed
[2024-09-27T15:40:08.087+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=predict_model_dag, execution_date=2024-09-27 13:39:54+00:00, run_id=manual__2024-09-27T13:39:54+00:00, run_start_date=2024-09-27 13:39:55.101858+00:00, run_end_date=2024-09-27 13:40:08.087468+00:00, run_duration=12.98561, state=failed, external_trigger=True, run_type=manual, data_interval_start=2024-09-26 00:00:00+00:00, data_interval_end=2024-09-27 00:00:00+00:00, dag_hash=d69314eb4107b40e51220d0a297377f1
[2024-09-27T15:44:21.231+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T15:49:21.271+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T15:50:10.125+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: predict_model_dag.test_mongo_conn_task manual__2024-09-27T13:50:09+00:00 [scheduled]>
[2024-09-27T15:50:10.125+0200] {scheduler_job_runner.py:495} INFO - DAG predict_model_dag has 0/16 running and queued tasks
[2024-09-27T15:50:10.126+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: predict_model_dag.test_mongo_conn_task manual__2024-09-27T13:50:09+00:00 [scheduled]>
[2024-09-27T15:50:10.127+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: predict_model_dag.test_mongo_conn_task manual__2024-09-27T13:50:09+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T15:50:10.127+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='predict_model_dag', task_id='test_mongo_conn_task', run_id='manual__2024-09-27T13:50:09+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2024-09-27T15:50:10.127+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'predict_model_dag', 'test_mongo_conn_task', 'manual__2024-09-27T13:50:09+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:50:10.137+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'predict_model_dag', 'test_mongo_conn_task', 'manual__2024-09-27T13:50:09+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:50:13.843+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='predict_model_dag', task_id='test_mongo_conn_task', run_id='manual__2024-09-27T13:50:09+00:00', try_number=1, map_index=-1)
[2024-09-27T15:50:13.852+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=predict_model_dag, task_id=test_mongo_conn_task, run_id=manual__2024-09-27T13:50:09+00:00, map_index=-1, run_start_date=2024-09-27 13:50:12.793184+00:00, run_end_date=2024-09-27 13:50:12.929945+00:00, run_duration=0.136761, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=47, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2024-09-27 13:50:10.126585+00:00, queued_by_job_id=38, pid=135682
[2024-09-27T15:50:19.655+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: predict_model_dag.fetch_data_task manual__2024-09-27T13:50:09+00:00 [scheduled]>
[2024-09-27T15:50:19.656+0200] {scheduler_job_runner.py:495} INFO - DAG predict_model_dag has 0/16 running and queued tasks
[2024-09-27T15:50:19.658+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: predict_model_dag.fetch_data_task manual__2024-09-27T13:50:09+00:00 [scheduled]>
[2024-09-27T15:50:19.661+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: predict_model_dag.fetch_data_task manual__2024-09-27T13:50:09+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T15:50:19.663+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='predict_model_dag', task_id='fetch_data_task', run_id='manual__2024-09-27T13:50:09+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T15:50:19.663+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'predict_model_dag', 'fetch_data_task', 'manual__2024-09-27T13:50:09+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:50:19.677+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'predict_model_dag', 'fetch_data_task', 'manual__2024-09-27T13:50:09+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:50:22.997+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='predict_model_dag', task_id='fetch_data_task', run_id='manual__2024-09-27T13:50:09+00:00', try_number=1, map_index=-1)
[2024-09-27T15:50:23.000+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=predict_model_dag, task_id=fetch_data_task, run_id=manual__2024-09-27T13:50:09+00:00, map_index=-1, run_start_date=2024-09-27 13:50:22.145872+00:00, run_end_date=2024-09-27 13:50:22.337563+00:00, run_duration=0.191691, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=49, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 13:50:19.661080+00:00, queued_by_job_id=38, pid=135775
[2024-09-27T15:54:21.345+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T15:56:04.682+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: predict_model_dag.test_mongo_conn_task manual__2024-09-27T13:56:03+00:00 [scheduled]>
[2024-09-27T15:56:04.685+0200] {scheduler_job_runner.py:495} INFO - DAG predict_model_dag has 0/16 running and queued tasks
[2024-09-27T15:56:04.685+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: predict_model_dag.test_mongo_conn_task manual__2024-09-27T13:56:03+00:00 [scheduled]>
[2024-09-27T15:56:04.691+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: predict_model_dag.test_mongo_conn_task manual__2024-09-27T13:56:03+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T15:56:04.698+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='predict_model_dag', task_id='test_mongo_conn_task', run_id='manual__2024-09-27T13:56:03+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2024-09-27T15:56:04.698+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'predict_model_dag', 'test_mongo_conn_task', 'manual__2024-09-27T13:56:03+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:56:04.729+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'predict_model_dag', 'test_mongo_conn_task', 'manual__2024-09-27T13:56:03+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:56:08.841+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='predict_model_dag', task_id='test_mongo_conn_task', run_id='manual__2024-09-27T13:56:03+00:00', try_number=1, map_index=-1)
[2024-09-27T15:56:08.856+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=predict_model_dag, task_id=test_mongo_conn_task, run_id=manual__2024-09-27T13:56:03+00:00, map_index=-1, run_start_date=2024-09-27 13:56:07.416062+00:00, run_end_date=2024-09-27 13:56:07.656461+00:00, run_duration=0.240399, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=51, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2024-09-27 13:56:04.685976+00:00, queued_by_job_id=38, pid=138522
[2024-09-27T15:56:13.003+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: predict_model_dag.fetch_data_task manual__2024-09-27T13:56:03+00:00 [scheduled]>
[2024-09-27T15:56:13.004+0200] {scheduler_job_runner.py:495} INFO - DAG predict_model_dag has 0/16 running and queued tasks
[2024-09-27T15:56:13.004+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: predict_model_dag.fetch_data_task manual__2024-09-27T13:56:03+00:00 [scheduled]>
[2024-09-27T15:56:13.006+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: predict_model_dag.fetch_data_task manual__2024-09-27T13:56:03+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T15:56:13.007+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='predict_model_dag', task_id='fetch_data_task', run_id='manual__2024-09-27T13:56:03+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T15:56:13.007+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'predict_model_dag', 'fetch_data_task', 'manual__2024-09-27T13:56:03+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:56:13.018+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'predict_model_dag', 'fetch_data_task', 'manual__2024-09-27T13:56:03+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T15:56:16.429+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='predict_model_dag', task_id='fetch_data_task', run_id='manual__2024-09-27T13:56:03+00:00', try_number=1, map_index=-1)
[2024-09-27T15:56:16.433+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=predict_model_dag, task_id=fetch_data_task, run_id=manual__2024-09-27T13:56:03+00:00, map_index=-1, run_start_date=2024-09-27 13:56:15.616284+00:00, run_end_date=2024-09-27 13:56:15.793342+00:00, run_duration=0.177058, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=53, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 13:56:13.005682+00:00, queued_by_job_id=38, pid=138610
[2024-09-27T15:56:16.468+0200] {dagrun.py:823} ERROR - Marking run <DagRun predict_model_dag @ 2024-09-27 13:56:03+00:00: manual__2024-09-27T13:56:03+00:00, state:running, queued_at: 2024-09-27 13:56:03.472254+00:00. externally triggered: True> failed
[2024-09-27T15:56:16.469+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=predict_model_dag, execution_date=2024-09-27 13:56:03+00:00, run_id=manual__2024-09-27T13:56:03+00:00, run_start_date=2024-09-27 13:56:04.608727+00:00, run_end_date=2024-09-27 13:56:16.469215+00:00, run_duration=11.860488, state=failed, external_trigger=True, run_type=manual, data_interval_start=2024-09-26 00:00:00+00:00, data_interval_end=2024-09-27 00:00:00+00:00, dag_hash=d69314eb4107b40e51220d0a297377f1
[2024-09-27T15:59:21.397+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T16:04:21.447+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T16:04:51.819+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: predict_model_dag.load_model_task scheduled__2024-09-26T00:00:00+00:00 [scheduled]>
[2024-09-27T16:04:51.820+0200] {scheduler_job_runner.py:495} INFO - DAG predict_model_dag has 1/16 running and queued tasks
[2024-09-27T16:04:51.820+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: predict_model_dag.load_model_task scheduled__2024-09-26T00:00:00+00:00 [scheduled]>
[2024-09-27T16:04:51.821+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: predict_model_dag.load_model_task scheduled__2024-09-26T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T16:04:51.822+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='predict_model_dag', task_id='load_model_task', run_id='scheduled__2024-09-26T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T16:04:51.822+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'predict_model_dag', 'load_model_task', 'scheduled__2024-09-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T16:04:51.828+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'predict_model_dag', 'load_model_task', 'scheduled__2024-09-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T16:04:55.118+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='predict_model_dag', task_id='load_model_task', run_id='scheduled__2024-09-26T00:00:00+00:00', try_number=1, map_index=-1)
[2024-09-27T16:04:55.122+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=predict_model_dag, task_id=load_model_task, run_id=scheduled__2024-09-26T00:00:00+00:00, map_index=-1, run_start_date=2024-09-27 14:04:53.656450+00:00, run_end_date=2024-09-27 14:04:54.144720+00:00, run_duration=0.48827, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=53, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 14:04:51.821115+00:00, queued_by_job_id=38, pid=141798
[2024-09-27T16:04:57.322+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: predict_model_dag.fetch_data_task manual__2024-09-27T14:04:34+00:00 [scheduled]>
[2024-09-27T16:04:57.323+0200] {scheduler_job_runner.py:495} INFO - DAG predict_model_dag has 1/16 running and queued tasks
[2024-09-27T16:04:57.323+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: predict_model_dag.fetch_data_task manual__2024-09-27T14:04:34+00:00 [scheduled]>
[2024-09-27T16:04:57.325+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: predict_model_dag.fetch_data_task manual__2024-09-27T14:04:34+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T16:04:57.326+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='predict_model_dag', task_id='fetch_data_task', run_id='manual__2024-09-27T14:04:34+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T16:04:57.326+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'predict_model_dag', 'fetch_data_task', 'manual__2024-09-27T14:04:34+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T16:04:57.334+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'predict_model_dag', 'fetch_data_task', 'manual__2024-09-27T14:04:34+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T16:04:59.586+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='predict_model_dag', task_id='fetch_data_task', run_id='manual__2024-09-27T14:04:34+00:00', try_number=1, map_index=-1)
[2024-09-27T16:04:59.589+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=predict_model_dag, task_id=fetch_data_task, run_id=manual__2024-09-27T14:04:34+00:00, map_index=-1, run_start_date=2024-09-27 14:04:58.953607+00:00, run_end_date=2024-09-27 14:04:59.098099+00:00, run_duration=0.144492, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=55, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 14:04:57.324754+00:00, queued_by_job_id=38, pid=141864
[2024-09-27T16:05:00.298+0200] {dagrun.py:823} ERROR - Marking run <DagRun predict_model_dag @ 2024-09-26 00:00:00+00:00: scheduled__2024-09-26T00:00:00+00:00, state:running, queued_at: 2024-09-27 14:04:49.133595+00:00. externally triggered: False> failed
[2024-09-27T16:05:00.299+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=predict_model_dag, execution_date=2024-09-26 00:00:00+00:00, run_id=scheduled__2024-09-26T00:00:00+00:00, run_start_date=2024-09-27 14:04:49.218267+00:00, run_end_date=2024-09-27 14:05:00.299601+00:00, run_duration=11.081334, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-26 00:00:00+00:00, data_interval_end=2024-09-27 00:00:00+00:00, dag_hash=d69314eb4107b40e51220d0a297377f1
[2024-09-27T16:05:00.310+0200] {dag.py:4180} INFO - Setting next_dagrun for predict_model_dag to 2024-09-27 00:00:00+00:00, run_after=2024-09-28 00:00:00+00:00
[2024-09-27T16:05:00.320+0200] {dagrun.py:823} ERROR - Marking run <DagRun predict_model_dag @ 2024-09-27 14:04:34+00:00: manual__2024-09-27T14:04:34+00:00, state:running, queued_at: 2024-09-27 14:04:34.466400+00:00. externally triggered: True> failed
[2024-09-27T16:05:00.326+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=predict_model_dag, execution_date=2024-09-27 14:04:34+00:00, run_id=manual__2024-09-27T14:04:34+00:00, run_start_date=2024-09-27 14:04:49.218481+00:00, run_end_date=2024-09-27 14:05:00.326827+00:00, run_duration=11.108346, state=failed, external_trigger=True, run_type=manual, data_interval_start=2024-09-26 00:00:00+00:00, data_interval_end=2024-09-27 00:00:00+00:00, dag_hash=d69314eb4107b40e51220d0a297377f1
[2024-09-27T16:09:22.636+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T16:14:22.668+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T16:15:07.644+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: predict_model_dag.fetch_data_task manual__2024-09-27T14:15:02+00:00 [scheduled]>
[2024-09-27T16:15:07.645+0200] {scheduler_job_runner.py:495} INFO - DAG predict_model_dag has 0/16 running and queued tasks
[2024-09-27T16:15:07.645+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: predict_model_dag.fetch_data_task manual__2024-09-27T14:15:02+00:00 [scheduled]>
[2024-09-27T16:15:07.647+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: predict_model_dag.fetch_data_task manual__2024-09-27T14:15:02+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T16:15:07.647+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='predict_model_dag', task_id='fetch_data_task', run_id='manual__2024-09-27T14:15:02+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T16:15:07.647+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'predict_model_dag', 'fetch_data_task', 'manual__2024-09-27T14:15:02+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T16:15:07.657+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'predict_model_dag', 'fetch_data_task', 'manual__2024-09-27T14:15:02+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T16:15:10.774+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='predict_model_dag', task_id='fetch_data_task', run_id='manual__2024-09-27T14:15:02+00:00', try_number=1, map_index=-1)
[2024-09-27T16:15:10.790+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=predict_model_dag, task_id=fetch_data_task, run_id=manual__2024-09-27T14:15:02+00:00, map_index=-1, run_start_date=2024-09-27 14:15:09.572234+00:00, run_end_date=2024-09-27 14:15:09.722433+00:00, run_duration=0.150199, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=60, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 14:15:07.646312+00:00, queued_by_job_id=38, pid=146285
[2024-09-27T16:15:10.825+0200] {dagrun.py:823} ERROR - Marking run <DagRun predict_model_dag @ 2024-09-27 14:15:02+00:00: manual__2024-09-27T14:15:02+00:00, state:running, queued_at: 2024-09-27 14:15:02.270410+00:00. externally triggered: True> failed
[2024-09-27T16:15:10.826+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=predict_model_dag, execution_date=2024-09-27 14:15:02+00:00, run_id=manual__2024-09-27T14:15:02+00:00, run_start_date=2024-09-27 14:15:03.143238+00:00, run_end_date=2024-09-27 14:15:10.826581+00:00, run_duration=7.683343, state=failed, external_trigger=True, run_type=manual, data_interval_start=2024-09-26 00:00:00+00:00, data_interval_end=2024-09-27 00:00:00+00:00, dag_hash=d69314eb4107b40e51220d0a297377f1
[2024-09-27T16:15:41.097+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: predict_model_dag.test_mongo_conn_task manual__2024-09-27T14:15:40+00:00 [scheduled]>
[2024-09-27T16:15:41.098+0200] {scheduler_job_runner.py:495} INFO - DAG predict_model_dag has 0/16 running and queued tasks
[2024-09-27T16:15:41.099+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: predict_model_dag.test_mongo_conn_task manual__2024-09-27T14:15:40+00:00 [scheduled]>
[2024-09-27T16:15:41.100+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: predict_model_dag.test_mongo_conn_task manual__2024-09-27T14:15:40+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T16:15:41.101+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='predict_model_dag', task_id='test_mongo_conn_task', run_id='manual__2024-09-27T14:15:40+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2024-09-27T16:15:41.102+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'predict_model_dag', 'test_mongo_conn_task', 'manual__2024-09-27T14:15:40+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T16:15:41.112+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'predict_model_dag', 'test_mongo_conn_task', 'manual__2024-09-27T14:15:40+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T16:15:44.382+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='predict_model_dag', task_id='test_mongo_conn_task', run_id='manual__2024-09-27T14:15:40+00:00', try_number=1, map_index=-1)
[2024-09-27T16:15:44.414+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=predict_model_dag, task_id=test_mongo_conn_task, run_id=manual__2024-09-27T14:15:40+00:00, map_index=-1, run_start_date=2024-09-27 14:15:43.622898+00:00, run_end_date=2024-09-27 14:15:43.759995+00:00, run_duration=0.137097, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=61, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2024-09-27 14:15:41.099849+00:00, queued_by_job_id=38, pid=146509
[2024-09-27T16:15:49.112+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: predict_model_dag.fetch_data_task manual__2024-09-27T14:15:40+00:00 [scheduled]>
[2024-09-27T16:15:49.112+0200] {scheduler_job_runner.py:495} INFO - DAG predict_model_dag has 0/16 running and queued tasks
[2024-09-27T16:15:49.113+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: predict_model_dag.fetch_data_task manual__2024-09-27T14:15:40+00:00 [scheduled]>
[2024-09-27T16:15:49.114+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: predict_model_dag.fetch_data_task manual__2024-09-27T14:15:40+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T16:15:49.115+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='predict_model_dag', task_id='fetch_data_task', run_id='manual__2024-09-27T14:15:40+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T16:15:49.115+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'predict_model_dag', 'fetch_data_task', 'manual__2024-09-27T14:15:40+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T16:15:49.125+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'predict_model_dag', 'fetch_data_task', 'manual__2024-09-27T14:15:40+00:00', '--local', '--subdir', 'DAGS_FOLDER/predict_model_dag.py']
[2024-09-27T16:15:52.747+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='predict_model_dag', task_id='fetch_data_task', run_id='manual__2024-09-27T14:15:40+00:00', try_number=1, map_index=-1)
[2024-09-27T16:15:52.752+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=predict_model_dag, task_id=fetch_data_task, run_id=manual__2024-09-27T14:15:40+00:00, map_index=-1, run_start_date=2024-09-27 14:15:51.906106+00:00, run_end_date=2024-09-27 14:15:52.104925+00:00, run_duration=0.198819, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=63, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 14:15:49.113986+00:00, queued_by_job_id=38, pid=146586
[2024-09-27T16:19:22.714+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T16:24:22.755+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T16:29:22.800+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T16:34:22.854+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T16:39:22.884+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T16:44:22.912+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T16:49:22.936+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T16:54:22.963+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T16:59:22.996+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T17:04:23.024+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T17:09:23.062+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T17:14:23.100+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T17:19:23.111+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T17:24:23.148+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T17:29:23.174+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T17:34:23.221+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T17:39:23.272+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T17:44:23.299+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T17:49:23.324+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T17:54:23.362+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T17:59:23.387+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T18:04:23.421+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T18:09:23.447+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T18:14:23.475+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T18:19:23.501+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T18:24:24.269+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T18:29:24.296+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T18:34:24.322+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T18:39:24.348+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T18:44:24.649+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
